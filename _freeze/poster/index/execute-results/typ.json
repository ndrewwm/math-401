{
  "hash": "0ca84e29dacbad3e6e538d3b0e5e1373",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Vector-valued Gaussian Processes\nexecute: \n  freeze: true\nbibliography: poster.bib\nnocite: |\n  @harlander2012reconstruction, @alvarez2012kernels, @williams2006gaussian, @chang2018r\nknitr:\n  opts_chunk:\n    echo: false\n    warning: false\n    message: false\nformat:\n  poster-typst:\n    size: \"48x36\"\n    poster-authors: \"Andrew Moore, Grady Wright (Advisor)\"\n    departments: \"Department of Mathematics\"\n    institution-logo: \"./images/boisestate-leftalignedlogo-2color-rgb.png\"\n    footer-text: \"Spring 2025, Senior Showcase\"\n    footer-url: \"https://ndrewwm.github.io/math-401\"\n    footer-emails: \"andrewmoore1@u.boisestate.edu\"\n    footer-color: \"0033A0\" #\"D64309\"\n    keywords: [\"Gaussian Processes\", \"Statistics\", \"Velocity Fields\"]\n---\n\n\n\n# Overview of Gaussian Processes\n\nGaussian processes generalize the multivariate Gaussian dist. and can describe probability distributions over functions. [@williams2006gaussian]\n\n## Multivariate Gaussian Distribution\n\n\n\n```{=typst}\n$ bold(z) in RR^N &tilde.op cal(N)_N (bold(mu), bold(Sigma)) \" \" z_i tilde.op cal(N)(mu_i, bold(Sigma)_(i i)) \\ \n  bold(mu) in RR^N &= (mu_1, mu_2, ..., mu_N)^top = (EE(z_1), EE(z_2), ..., EE(z_N))^top \\ \n  bold(Sigma) in RR^(N times N) &= EE((bold(z) - mu)(bold(z) - mu)^top) = [op(\"cov\")(z_i, z_j)]_(i,j = 1)^N $\n```\n\n\n\n## Gaussian Processes (GPs)\n\n\n\n```{=typst}\n- GP: an uncountably infinite collection of random variables; any finite sample is a draw from a MV Gaussian distribution.\n- GPs fully specified by _mean_ and _covariance (kernel)_ functions.\n- The covariance function $k$ must produce a positive semi-definite matrix.\n- Squared exponential kernel, $k: RR^p times RR^p -> RR$: $ k(x, x') = alpha^2 op(\"exp\")(-1/(2rho^2) ||x - x'||^2). $\n// - $||dot||$ is the Euclidean Norm: $||bold(x)|| = sqrt(x_1 + x_2 + dots.h.c + x_N)$\n- $alpha$ and $rho$ are _hyperparameters_ (chosen, or estimated from data)\n```\n\n\n\n# Gaussian Process Regression -- Univariate $\\mathbf{y}$\n\n\n\n```{=typst}\n```\n\n::: {.cell}\n\n:::\n\n```{=typst}\n$ S = (bold(x), bold(y)) &= { (x_i, y_i) : x_i, y_i in RR, i in 1, 2, ..., N } \\\n  f \" \" ~ \" \" cal(\"GP\")(bold(0), k) \" \" & \" \"\n  bold(y)_* \" \" ~ \" \" cal(N)_M (bold(0), k(bold(x)_*, bold(x)_*)) \\\n  k(bold(x)_*, bold(x)_*) in RR^(M times M) &= [k(x_(*i), x_(*j))]_(i,j = 1)^M. $\n\n// - Draws from the prior distribution (shown in grey) don't necessarily agree with the data points.\n// - Kernel choice determines properties of $f$ (e.g., smoothness)\n```\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-typst/unnamed-chunk-2-1.svg)\n:::\n:::\n\n```{=typst}\n$ bold(y)_* | bold(x), bold(y), bold(x)_* \" \" &~ \" \" cal(N)_M (hat(mu), hat(Sigma)) \\\nhat(mu) in RR^M &= k(bold(x)_*, bold(x)) k(bold(x), bold(x))^(-1) bold(y) \\\nhat(Sigma) in RR^(M times M) &= k(bold(x)_*, bold(x)_*) - k(bold(x)_*, bold(x))k(bold(x), bold(x))^(-1)k(bold(x)_*, bold(x))^top $\n```\n\n```{=typst}\n$ k(bold(x), bold(x)) in RR^(N times N) &= [k(x_i, x_j)]_(i,j = 1)^N \\\nk(bold(x)_*, bold(x)) in RR^(M times N) &= [k(x_(*i), x_j)]_(i,j = 1)^(M,N). $\n```\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-typst/unnamed-chunk-3-1.svg)\n:::\n:::\n\n\n\n# Multioutput GPR -- Vector-valued $\\mathbf{y}$\n\n\n\n```{=typst}\n- Velocity fields: $bold(X), bold(Y) in RR^(N times 2), \" \" bold(y) &in RR^(2N) = \"vec\"(Y), \" \" bold(X)_* in RR^(M times 2)$\n```\n\n\n\n<!-- // - Idea: columns of $bold(Y)$ might not be independent -->\n- Intrinsic Coregionalization Model (ICM) [@alvarez2012kernels] [@bonilla2007multi]\n\n\n\n```{=typst}\n$ bold(y)_* | bold(X), bold(y), bold(X)_* \" \" &~ \" \" cal(N)_(2M) (hat(mu), hat(Sigma)) \\\n  hat(mu) in RR^(2M) &= K_(bold(X)_* bold(X)) K_(bold(X) bold(X))^(-1) bold(y) \\\n  hat(Sigma) in RR^(2M times 2M) &= K_(bold(X)_* bold(X)_*) - K_(bold(X)_* bold(X)) K_(bold(X) bold(X))^(-1) K_(bold(X)_* bold(X))^top \\\n  K_(bold(X) bold(X)) in RR^(2N times 2N) &= B times.circle k(bold(X), bold(X)) \\\n  K_(bold(X)_* bold(X)) in RR^(2M times 2N) &= B times.circle k(bold(X)_*, bold(X)) \\ \n  K_(bold(X)_* bold(X)_*) in RR^(2M times 2M) &= B times.circle k(bold(X)_*, bold(X)_*) \\\n  B in RR^(2 times 2) &= \"corr\"(bold(Y)) = (\n  (angle.l bold(y)_i - overline(bold(y))_i, bold(y)_j - overline(bold(y))_j angle.r) / \n    (||bold(y)_i - overline(bold(y))_i|| ||bold(y)_j - overline(bold(y))_j||)\n)_(i,j = 1)^2 $\n```\n\n\n\n**Case study:** Hurricane Isabel Simulation [@chang2018r]\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-typst/unnamed-chunk-7-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n\n<!-- PIV DATA -->\n\n**Case study:** Particle Image Velocimetry [@harlander2012reconstruction]\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-typst/unnamed-chunk-10-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n*Note:* colors reflect <span style=\"color: #D64309\">sample data</span>, <span style=\"color: #0033A0\">posterior mean</span>, and <span style=\"color: grey;\">test points.</span>\n\n\n\n```{=typst}\n\\\n```",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}